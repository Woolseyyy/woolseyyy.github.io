<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Haoqian Wu</title>

  <meta name="author" content="Haoqian Wu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:25%;max-width:25%">
                  <a href="myAvatar.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="myAvatar.jpg"
                      class="hoverZoomLink"></a>
                </td>
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Haoqian Wu</name>
                  </p>

                  Email: wuhaoqian@sync-xyz.com
                  <p style="text-align:center">
                    <a href="https://scholar.google.com/citations?user=vVVxH7IAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/Woolseyyy">Github</a>
                  </p>

                  <p>
                    I am the CEO & Co-founder of <a href="https://sync-xyz.com">Sync</a>, building the next generation of AI-native companionship products designed to enhance emotional connection, creativity, and intelligence in everyday life.
                    Previously, I founded MR Game Studio <strong>D-Fissure</strong>, leading a 10-person team to ship four indie games, one of which generated over ¥1M and was acquired by a major tech company.
                  </p>

                  <p>
                    Before founding Sync, I worked as an AI Research Scientist at 
                    <a href="https://fuxi.163.com/">NetEase Fuxi Lab</a>, where I developed AI avatar systems deployed in 
                    <i>Justice Mobile</i> and <i>Naraka: Bladepoint Mobile</i>, serving tens of millions of users. Prior to that, I worked at 
                    <strong>Kuaishou</strong> on 0-to-1 AI digital human initiatives.
                  </p>

                  <p>
                    I received my Master’s degree from
                    <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, advised by
                    <a href="https://person.zju.edu.cn/en/xilics#0">Prof. Xi Li</a>, and my Bachelor’s degree in Computer Science from the same institution. I have published <strong>5 top-tier papers</strong> in multimodal AI, 3D vision, and neural rendering.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <heading>Projects</heading>
                </td>
              </tr>

              <!-- Shira -->
              <tr>
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <strong>Shira</strong> &nbsp;&nbsp;<i>AI-native virtual companion</i>
                  <br>
                  <a href="https://xiaomiaoxila.com" target="_blank">Website</a>
                  <br>
                  A deeply emotional AI feline companion — not just a pet, but a virtual being who grows with you, remembers you,
                  cares about you, and builds a lasting bond. Designed as an <b>AI-native emotional companion game</b> with persistent memory and evolving personality.
                </td>
              </tr>

              <!-- PatPat -->
              <tr>
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <strong>PatPat</strong> &nbsp;&nbsp;<i>Mixed-Reality rhythm music game</i>
                  <br>
                  <a href="https://d-fissure.com/patpat/" target="_blank">Website</a>
                  <br>
                  A creative rhythm game where players tap on their real desk to generate beats in sync with dynamic music. 
                  A physical + digital rhythm playground that blends tactile interaction with musical immersion.
                </td>
              </tr>

              <!-- Hey Mosquito -->
              <tr>
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <strong>Hey Mosquito!</strong> &nbsp;&nbsp;<i>Mixed-Reality action game</i>
                  <br>
                  <a href="https://d-fissure.com/heymosquito/" target="_blank">Website</a>
                  <br>
                  The ultimate mosquito-swatting MR experience — put on a headset and use your bare hands to swat incoming mosquitoes 
                  from all directions. 
                </td>
              </tr>

            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <heading>Research</heading>
                </td>
              </tr>

              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [5]&nbsp&nbsp<papertitle>ICE: Interactive 3D Game Character Editing via Dialogue</papertitle>
                  <br>
                  <a href="https://woolseyyy.github.io/" target="_blank"><strong>Haoqian Wu</strong></a>, 
                  Minda Zhao,
                  Zhipeng Hu, 
                  <a href="https://scholar.google.com/citations?user=NYLsVscAAAAJ&hl=zh-CN" target="_blank">Lincheng Li</a>,
                  Weijie Chen,
                  Rui Zhao,
                  Changjie Fan,
                  <a href="https://sites.google.com/view/xinyus-homepage/Home" target="_blank">Xin Yu</a>
                  <br>
                  <em>TMM</em>, 2024&nbsp
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/10949063">paper</a> /
                  <a href="https://iceedit.github.io/">project page</a>
                  <br>
                  We propose an Interactive Character Editing framework (ICE) to achieve a multi-round dialogue-based refinement process. 
                </td>
              </tr>

              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [4]&nbsp&nbsp<papertitle>Text-Guided 3D Face Synthesis -- From Generation to Editing</papertitle>
                  <br>
                  Yunjie Wu,
                  Yapeng Meng,
                  Zhipeng Hu, 
                  <a href="https://scholar.google.com/citations?user=NYLsVscAAAAJ&hl=zh-CN" target="_blank">Lincheng Li</a>,
                  <a href="https://woolseyyy.github.io/" target="_blank"><strong>Haoqian Wu</strong></a>, 
                  Kun Zhou,
                  Weiwei Xu,
                  <a href="https://sites.google.com/view/xinyus-homepage/Home" target="_blank">Xin Yu</a>
                  <br>
                  <em>CVPR</em>, 2024&nbsp
                  <br>
                  <a href="https://arxiv.org/abs/2312.00375">paper</a> /
                  <a href="https://faceg2e.github.io/">project page</a>
                  <br>
                  We propose a unified text-guided framework from face generation to editing.
                </td>
              </tr>

              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [3]&nbsp&nbsp<papertitle>NeFII: Inverse Rendering for Reflectance Decomposition with Near-Field Indirect Illumination</papertitle>
                  <br>
                  <a href="https://woolseyyy.github.io/" target="_blank"><strong>Haoqian Wu</strong></a>, 
                  Zhipeng Hu, 
                  <a href="https://scholar.google.com/citations?user=NYLsVscAAAAJ&hl=zh-CN" target="_blank">Lincheng Li</a>,
                  <a href="https://seekever.github.io/" target="_blank">Yongqiang Zhang</a>,
                  Changjie Fan,
                  <a href="https://sites.google.com/view/xinyus-homepage/Home" target="_blank">Xin Yu</a>
                  <br>
                  <em>CVPR</em>, 2023&nbsp
                  <br>
                  <a href="https://arxiv.org/abs/2303.16617">paper</a> /
                  <a href="https://woolseyyy.github.io/nefii/">project page</a>
                  <br>
                  We introduce the Monte Carlo sampling based path tracing and cache the indirect illumination as neural radiance, enabling a physics-faithful and easy-to-optimize inverse rendering method.
                </td>
              </tr>

              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [2]&nbsp&nbsp<papertitle>Towards Unbiased Volume Rendering of Neural Implicit Surfaces with Geometry Priors</papertitle>
                  <br>
                  <a href="https://seekever.github.io/" target="_blank">Yongqiang Zhang</a>,
                  Zhipeng Hu,
                  <a href="https://woolseyyy.github.io/" target="_blank"><strong>Haoqian Wu</strong></a>,
                  Minda Zhao,
                  <a href="https://scholar.google.com/citations?user=NYLsVscAAAAJ&hl=zh-CN" target="_blank">Lincheng Li</a>,
                  Zhengxia Zou,
                  Changjie Fan
                  <br>
                  <em>CVPR</em>, 2023&nbsp
                  <br>
                  <a href="https://seekever.github.io/unbiasSDF/">project page</a>
                  <br>
                  We revise and provide an additional condition for the unbiased volume rendering. Following this analysis, we propose a new rendering method by scaling the SDF field with the angle between the viewing direction and the surface normal vector.
                </td>
              </tr>

              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  [1]&nbsp&nbsp<papertitle>Condition-Aware Comparison Scheme for Gait Recognition</papertitle>
                  <br>
                  <a href="https://woolseyyy.github.io/" target="_blank"><strong>Haoqian Wu</strong></a>,
                  Tian Jian,
                  Yongjian Fu,
                  Bin Li,
                  <a href="https://person.zju.edu.cn/en/xilics#927721" target="_blank">Xi Li</a>
                  <br>
                  <em>TIP</em>, 2020&nbsp
                  <br>
                  <a href="https://ieeexplore.ieee.org/document/9275377">paper</a>
                  <br>
                  We propose a condition-aware comparison scheme to measure gait pairs’ similarity via a novel module named Instructor. Also, we present a geometry-guided data augmentation approach (Dresser) to enrich dressing conditions. Furthermore, to enhance the gait representation, we propose to model temporal local information from coarse to fine. 
                </td>
              </tr>

            </tbody>
          </table>

          <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr>
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <heading>Open-source</heading>
                  <p>
                    In my spare time, I’ve been actively contributing to building an all-in-one open-source satellite
                    stereo
                    toolbox called <a href="https://github.com/Kai-46/SatelliteSfM">SatelliteSfM</a>, in order to
                    facilitate latest advances in 3D computer vision to satellite domain.
                  </p>
                </td>
              </tr>
            </tbody>
          </table> -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Kudos to <a href="https://jonbarron.info/">Dr. Jon Barron</a> for sharing his website template.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>